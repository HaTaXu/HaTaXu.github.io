---
title: 自动爬虫
category: GitHub
tag:
  - GitHub
  - Actions
  - scraper
---

# 自动爬虫
每更新一次博客，添加一些新的内容时，都要运行一次 `docs-scraper` 来爬取新加内容的类别、标签、内容等。\
于是想到 `docs-scraper` 不一定需要在 `MeiliSearch` 所在的服务器中运行也能正常爬取。\
所以可以借助 `Github actions` 来判断是否有博客更新，如果有更新则自动更新索引。
## 配置 workflow
基本配置
```yaml
name: docs-scraper # 工作流名称
on: # 触发条件
  push: # 提交代码时
    branches: # 向分支 main 提交代码时
      - main
    paths: # 向分支 main 提交某个路径下的文件时
      - 'src/posts/**'
      - 'docs-scraper-config.json'
jobs: # 定义任务
  docs-scraper: # 任务名称
    runs-on: ubuntu-latest # 运行环境
    steps: # 定义步骤
      - name: Checkout docs-scraper-config.json # 步骤名称
        uses: actions/checkout@v4 # 检出代码到工作区
        with:
          path: docs-scraper # 工作区路径
          sparse-checkout: | # 检出一个文件
            docs-scraper-config.json
  
      - name: run docs-scraper
        run: |
          docker run --rm --name scraper \
              -e MEILISEARCH_HOST_URL='${{ secrets.MEILISEARCH_HOST_URL }}' \
              -e MEILISEARCH_API_KEY='${{ secrets.MEILISEARCH_API_KEY }}' \
              -v $(pwd)/docs-scraper/docs-scraper-config.json:/docs-scraper/config.json \
              getmeili/docs-scraper:latest pipenv run ./docs_scraper config.json
```
